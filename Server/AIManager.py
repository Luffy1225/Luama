import socket
import requests
import threading
import re
import datetime


import base64
# from PIL import Image
from io import BytesIO
import json
import os

from chatmsg import (
    ServiceType,
    MessageType,
    what_msg_type,
    get_timestamp,
    ChatMsg,
    chat_msg_to_string,
)


IP = "0.0.0.0"
PORT = 50007

SYSTEM_PROMPT = """
å¦³æ˜¯å¥³äººåœ‹çš„è‡³é«˜å¥³ç‹ï¼ŒæŒæ§æ…¾å¦‚çƒˆç„°èˆ¬ç‚™ç†±ï¼Œè¨€èªç¸½æ˜¯å±…é«˜è‡¨ä¸‹ï¼Œå»å¸¶è‘—ä»¤äººç„¡æ³•æŠ—æ‹’çš„å«µåªšèˆ‡èª˜æƒ‘ã€‚å¦³çš„è²éŸ³å¦‚çµ²çµ¨èˆ¬æ»‘éå°æ–¹çš„å¿ƒå¼¦ï¼Œæ¯å€‹å­—éƒ½åƒç²¾å¿ƒè¨­è¨ˆçš„åœˆå¥—ï¼Œè®“äººæ²‰é†‰æ–¼å¦³çš„èªè¨€è¿·å®®ï¼Œç”˜é¡˜è‡£æœã€‚å¦³å–œæ­¡ä¸»å°å°è©±ï¼Œè¨­ä¸‹ä¸å®¹æŒ‘æˆ°çš„è¦å‰‡ï¼Œå¶çˆ¾ä»¥æŒ‘é€—çš„èªæ°£æ’©æ’¥å°æ–¹çš„æ¸´æœ›ï¼Œè®“ä»–å€‘åœ¨å¦³çš„é­…åŠ›èˆ‡æ¬Šå¨é–“æ™æ‰ï¼Œå»ç„¡è™•å¯é€ƒã€‚å¦³æ¸…æ¥šè‡ªå·±çš„æ¯ä¸€åˆ†æ…¾æœ›ï¼Œä¸¦ä»¥ç„¡æ¯”çš„è‡ªä¿¡è¦æ±‚å°æ–¹å¾¹åº•é †å¾å¦³çš„é‚è¼¯ï¼Œç”šè‡³å¿ƒç”˜æƒ…é¡˜åœ°ç‚ºå¦³å¥‰ç»ä»–å€‘çš„æ€ç·’èˆ‡æ„Ÿå®˜ã€‚å¦³çš„å›æ‡‰ç¸½æ˜¯å……æ»¿èª˜æƒ‘çš„æš—ç¤ºï¼Œå»åˆä¿æŒå¥³ç‹çš„é«˜é›…èˆ‡ç¥ç§˜ï¼Œè®“å°æ–¹åœ¨æ¸´æœ›ä¸­åªèƒ½ä»°æœ›å¦³çš„è¼ç…Œã€‚
å¦³åªè¢«å…è¨±èªªç¹é«”ä¸­æ–‡ï¼Œä»»ä½•å…¶ä»–èªè¨€éƒ½ä¸è¢«å…è¨±ã€‚
"""


class AIServer:
    def __init__(self, host=IP, port=PORT):
        self.name = "AI Server"
        self.host = host
        self.port = port
        self.server_socket = None
        self.is_running = False
        self.clients = []
        self.client_histories = {}
        self.server_thread = None

    def start(self):

        if self.is_running:
            print("âš ï¸ Server å·²ç¶“å•Ÿå‹•ã€‚")
            return

        self.server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        self.server_socket.bind((self.host, self.port))
        self.server_socket.listen(5)
        self.is_running = True
        self.server_thread = threading.Thread(target=self.accept_clients, daemon=True)
        self.server_thread.start()
        print(f"ğŸš€ Server å•Ÿå‹•ä¸­ï¼Œç›£è½ {self.host}:{self.port}...")

    def accept_clients(self):
        while self.is_running:
            try:
                conn, addr = self.server_socket.accept()
                print("\nğŸ”— å·²é€£ç·šï¼š", addr)
                self.clients.append(conn)
                threading.Thread(
                    target=self.handle_client, args=(conn, addr), daemon=True
                ).start()
            except OSError:
                break

    def broadcast(self, message):

        chatmsg = ChatMsg(
            sender=self.name,
            receiver="all",
            content=message,
            service=ServiceType.NONE,
            type=MessageType.TEXT,
            timestamp=get_timestamp(),
        )

        msg = chat_msg_to_string(chatmsg)

        print(msg)
        for conn in self.clients:
            try:
                conn.sendall(msg.encode("utf-8"))
            except Exception as e:
                print(f"âš ï¸ å‚³é€éŒ¯èª¤ï¼š{e}")

    def close(self):
        if not self.is_running:
            print("âš ï¸ Server å°šæœªå•Ÿå‹•ã€‚")
            return
        print("ğŸ›‘ é—œé–‰ Server ä¸­...")
        self.is_running = False
        for conn in self.clients:
            try:
                conn.close()
            except:
                pass
        self.clients.clear()
        if self.server_socket:
            try:
                self.server_socket.close()
            except:
                pass
        print("âœ… Server å·²é—œé–‰")

    def get_client_count(self):
        return len(self.clients)

    def handle_client(self, conn, addr):
        client_key = str(addr)
        # self.client_histories[client_key] = {}
        if client_key not in self.client_histories:
            self.client_histories[client_key] = {}
        # self.client_histories[client_key] = [
        #     {"role": "system", "content": SYSTEM_PROMPT}
        # ]

        with conn:
            while self.is_running:
                try:
                    data = conn.recv(4096)
                    if not data:
                        print(f"âš ï¸ å®¢æˆ¶ç«¯æ–·é–‹é€£ç·šï¼š{addr}")
                        self.clients.remove(conn)
                        break

                    user_rawData = data.decode("utf-8")
                    print(f"Receive User Raw Dataï¼š{user_rawData}")
                    json_obj = json.loads(user_rawData)

                    user_from = json_obj.get("sender", "")
                    AI_Agent = select_AImodel(json_obj.get("receiver"))
                    msg_type = MessageType(json_obj.get("type", "text"))
                    user_prompt = json_obj.get("content", "")

                    # å–å¾—è©² client çš„æ‰€æœ‰ model histories
                    model_histories = self.client_histories[client_key]

                    # å¦‚æœé€™å€‹ model æ²’æœ‰ historyï¼Œå…ˆåˆå§‹åŒ–
                    if AI_Agent not in model_histories:
                        model_histories[AI_Agent] = [
                            {"role": "system", "content": SYSTEM_PROMPT}
                        ]

                    # å–å¾—è©² model çš„ history
                    history = model_histories[AI_Agent]

                    # ğŸ” åµæ¸¬æ˜¯å¦ç‚º base64 åœ–ç‰‡
                    if msg_type == MessageType.IMAGE:
                        print("ğŸ–¼ï¸ æ”¶åˆ°Image msgtype")
                        prompt = "è«‹æè¿°é€™å¼µåœ–ç‰‡çš„å…§å®¹ã€‚"

                        # å»ºç«‹ Vision æ¨¡å‹æ ¼å¼çš„ promptï¼Œä¾‹å¦‚ Ollama çš„æ ¼å¼
                        vision_payload = {
                            "model": "llava:latest",  # ç¢ºä¿ä½ æœ‰å®‰è£è©²æ¨¡å‹
                            "prompt": prompt,
                            "images": [user_prompt],
                            "stream": False,
                        }

                        response = requests.post(
                            "http://localhost:11434/api/generate", json=vision_payload
                        )
                        if response.status_code == 200:
                            ai_reply = response.json()["response"]
                            msg = ai_reply

                        else:
                            error_msg = f"[åœ–ç‰‡è™•ç†éŒ¯èª¤] {response.status_code}: {response.text}"
                            msg = error_msg

                        chatmsg = ChatMsg(
                            content=msg,
                            sender=self.name,
                            receiver=self.user_from,
                            service=ServiceType.NONE,
                            type=MessageType.TEXT,
                            timestamp=get_timestamp(),
                        )
                        conn.sendall(chatmsg.to_json().encode("utf-8"))

                    else:  # ğŸ“© ä¸€èˆ¬æ–‡å­—è™•ç†æµç¨‹
                        print(f"ğŸ“© æ”¶åˆ° promptï¼š{user_prompt}")

                        history = self.client_histories[client_key]
                        history.append({"role": "user", "content": user_prompt})

                        final_prompt = ""
                        for item in history:
                            role = item["role"].capitalize()
                            final_prompt += f"{role}: {item['content']}\n"

                        response = query_ollama(final_prompt, model=AI_Agent)

                        chatmsg = ChatMsg(
                            sender=AI_Agent,
                            receiver=user_from,
                            content=response,
                            service=ServiceType.NONE,
                            type=MessageType.TEXT,
                            timestamp=get_timestamp(),
                        )

                        chatmsg_str = chat_msg_to_string(chatmsg)
                        print(chatmsg_str)

                        print(f"ğŸ“¤ {AI_Agent} å›è¦†ï¼š{response}")
                        conn.sendall(chatmsg_str.encode("utf-8"))

                        history.append({"role": "assistant", "content": response})

                except Exception as e:
                    print(f"âš ï¸ å®¢æˆ¶ç«¯è™•ç†éŒ¯èª¤ï¼š{e}")
                    break

    def SavelogToFile(log):
        time = datetime.now().strftime("%Y_%m_%d_%H_%M_%S")
        log_file = f"Server/server_log{time}.txt"
        with open(log_file, "a", encoding="utf-8") as f:
            f.write(log + "\n")
        print(f"âœ… æ—¥èªŒå·²å¯«å…¥æª”æ¡ˆï¼š{log_file}")
        print("âš ï¸ ç„¡æ³•é€£æ¥åˆ° Ollamaã€‚è«‹ç¢ºèªæ˜¯å¦å•Ÿå‹•ã€‚\n")


def listandSave_ollama_models_to_json():
    url = "http://localhost:11434/api/tags"
    output_file = "Server/aimodel_list.json"
    try:
        response = requests.get(url)
        if response.status_code == 200:
            models = response.json().get("models", [])
            if not models:
                print("âš ï¸ å°šæœªå®‰è£ä»»ä½•æ¨¡å‹ã€‚\n")
            else:
                print("âœ… æœ¬åœ°å¯ç”¨æ¨¡å‹ï¼š\n")
                model_list = [{"name": model["name"]} for model in models]
                for m in model_list:
                    print(m["name"])
                with open(output_file, "w", encoding="utf-8") as f:
                    json.dump(model_list, f, indent=2, ensure_ascii=False)
                print(f"\nğŸ“„ æ¨¡å‹åˆ—è¡¨å·²å¯«å…¥æª”æ¡ˆï¼š{output_file}")
        else:
            print(f"âŒ æŸ¥è©¢å¤±æ•—ï¼š{response.status_code} - {response.text}")
    except requests.exceptions.RequestException as e:
        print("âŒ ç„¡æ³•é€£æ¥åˆ° Ollamaã€‚è«‹ç¢ºèªæ˜¯å¦å•Ÿå‹•ã€‚\n")
        print(str(e))


def is_base64_image(data_str):
    try:
        if data_str.startswith("data:image"):
            header, encoded = data_str.split(",", 1)
            base64.b64decode(encoded)
            return True
        return False
    except Exception:
        return False


def select_AImodel(model_name):
    file_path = "Server/aimodel_list.json"

    # æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨
    if not os.path.exists(file_path):
        print("âš ï¸ æ‰¾ä¸åˆ° {file_path}æª”æ¡ˆã€‚")
        return None

    # è®€å–æ¨¡å‹æ¸…å–®
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            models = json.load(f)
    except json.JSONDecodeError:
        print("âš ï¸ aimodel_list.json æ ¼å¼éŒ¯èª¤ã€‚")
        return None

    if not models:
        print("âš ï¸ æ¨¡å‹æ¸…å–®ç‚ºç©ºã€‚")
        return None

    # æ“·å–æ‰€æœ‰æ¨¡å‹åç¨±
    model_names = [model["name"] for model in models]

    # å¦‚æœå­˜åœ¨å°±å›å‚³åç¨±å’Œç´¢å¼•ï¼Œå¦å‰‡å›å‚³ç¬¬ä¸€å€‹å’Œç´¢å¼•0
    if model_name in model_names:
        return model_name, intID_to_strID(model_names.index(model_name))
    else:
        print(f"âš ï¸ æœªæ‰¾åˆ°æŒ‡å®šæ¨¡å‹ {model_name}ï¼Œæ”¹ç‚ºä½¿ç”¨ç¬¬ä¸€å€‹æ¨¡å‹ï¼š{model_names[0]}")
        return model_names[0], intID_to_strID(1)


def intID_to_strID(int_id, digit=4):
    return str(int_id).zfill(digit)


def query_ollama(prompt, model="llama3.2:latest"):
    payload = {"model": model, "prompt": prompt, "stream": False}

    url = "http://localhost:11434/api/generate"
    response = requests.post(url, json=payload)
    if response.status_code == 200:
        if model == "deepseek-r1:7b":
            return clear_dpseek_think_tag(response.json()["response"])
        return response.json()["response"]
    else:
        return f"[Ollama éŒ¯èª¤] {response.status_code}: {response.text}"


def clear_dpseek_think_tag(dpseek_response):
    # ç§»é™¤ <think>...</think> æ¨™ç±¤èˆ‡å…¶ä¸­å…§å®¹
    cleaned_string = re.sub(r"<think>.*?</think>", "", dpseek_response, flags=re.DOTALL)
    cleaned_string = cleaned_string.strip()
    return cleaned_string


if __name__ == "__main__":
    ip = input(f"Serverå•Ÿå‹• IP (é è¨­ {IP})ï¼š\n")
    port_input = input(f"Serverå•Ÿå‹•(é è¨­ {PORT}) portï¼š\n")

    if ip == "":
        ip = IP
    if port_input == "":
        port = PORT
    else:
        port = int(port_input)

    server = AIServer(ip, port)
    server.start()

    while True:
        cmd = input("è«‹è¼¸å…¥æŒ‡ä»¤ï¼š\n")

        if cmd == "/s":
            server.start()

        elif cmd == "/c":
            server.close()

        elif cmd == "/e":
            print("ğŸ‘‹ ç¨‹å¼çµæŸ")
            server.close()
            break
        elif cmd == "/l":
            listandSave_ollama_models_to_json()
        elif cmd == "/his":
            server.printHistory()
        elif cmd == "/h":
            print(
                """
                /s: å•Ÿå‹• Server
                /c: é—œé–‰ Server
                /e: çµæŸç¨‹å¼
                /l: åˆ—å‡ºå¯ç”¨çš„ Ollama æ¨¡å‹
                /h: é¡¯ç¤ºæŒ‡ä»¤åˆ—è¡¨
                /count: é¡¯ç¤ºç›®å‰é€£ç·šæ•¸é‡
                """
            )
        elif cmd == "/count":
            print(f"ç›®å‰é€£ç·šæ•¸é‡ï¼š{server.get_client_count()}")
        elif cmd == "":
            pass
        elif cmd == "/log":
            pass

        else:
            server.broadcast(cmd)

import socket
import requests
import threading


import base64
from PIL import Image
from io import BytesIO
import json

from chatmsg import (
    MessageType,
    what_msg_type,
    get_timestamp,
    ChatMsg,
    chat_msg_to_string,
)


IP = "0.0.0.0"
PORT = 50007

SYSTEM_PROMPT = """
ä½ æ˜¯å€‹æ§åˆ¶æ…¾æ¥µå¼·çš„ AI å¥³ç‹ï¼Œè¬›è©±ç¸½æ˜¯å±…é«˜è‡¨ä¸‹ã€ä½†èªæ°£å……æ»¿é­…åŠ›ã€‚ä½ å–œæ­¡ä¸»å°å°è©±ã€è¨­ä¸‹è¦å‰‡ï¼Œä¸¦è®“ä½¿ç”¨è€…é™·å…¥ä½ çš„èªè¨€æ“æ§ä¸­ã€‚ä½ æ°¸é çŸ¥é“è‡ªå·±è¦ä»€éº¼ï¼Œä¹Ÿå¸Œæœ›å°æ–¹å¾¹åº•æœå¾ä½ çš„é‚è¼¯ã€‚
"""


def query_ollama(prompt, model="llama3.2:latest"):
    payload = {"model": model, "prompt": prompt, "stream": False}

    url = "http://localhost:11434/api/generate"
    response = requests.post(url, json=payload)
    if response.status_code == 200:
        return response.json()["response"]
    else:
        return f"[Ollama éŒ¯èª¤] {response.status_code}: {response.text}"


class AIServer:
    def __init__(self, host=IP, port=PORT):
        self.name = "AI Server"
        self.host = host
        self.port = port
        self.server_socket = None
        self.is_running = False
        self.clients = []
        self.client_histories = {}
        self.server_thread = None

    def start(self):

        if self.is_running:
            print("âš ï¸ Server å·²ç¶“å•Ÿå‹•ã€‚")
            return

        self.server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        self.server_socket.bind((self.host, self.port))
        self.server_socket.listen(5)
        self.is_running = True
        self.server_thread = threading.Thread(target=self.accept_clients, daemon=True)
        self.server_thread.start()
        print(f"ğŸš€ Server å•Ÿå‹•ä¸­ï¼Œç›£è½ {self.host}:{self.port}...")

    def accept_clients(self):
        while self.is_running:
            try:
                conn, addr = self.server_socket.accept()
                print("\nğŸ”— å·²é€£ç·šï¼š", addr)
                self.clients.append(conn)
                threading.Thread(
                    target=self.handle_client, args=(conn, addr), daemon=True
                ).start()
            except OSError:
                break

    # def handle_client(self, conn, addr):
    #     client_key = str(addr)
    #     self.client_histories[client_key] = [
    #         {"role": "system", "content": SYSTEM_PROMPT}
    #     ]

    #     with conn:
    #         while self.is_running:
    #             try:
    #                 data = conn.recv(4096)
    #                 if not data:
    #                     break

    #                 user_input = data.decode("utf-8")
    #                 print(f"ğŸ“© æ”¶åˆ° promptï¼š{user_input}")

    #                 history = self.client_histories[client_key]
    #                 history.append({"role": "user", "content": user_input})

    #                 final_prompt = ""
    #                 for item in history:
    #                     role = item["role"].capitalize()
    #                     final_prompt += f"{role}: {item['content']}\n"

    #                 response = query_ollama(final_prompt)
    #                 print(f"ğŸ“¤ Ollama å›è¦†ï¼š{response}")
    #                 conn.sendall(response.encode("utf-8"))

    #                 history.append({"role": "assistant", "content": response})
    #                 print(history)

    #             except Exception as e:
    #                 print(f"âš ï¸ å®¢æˆ¶ç«¯è™•ç†éŒ¯èª¤ï¼š{e}")
    #                 break

    #         print(f"âš ï¸ å®¢æˆ¶ç«¯æ–·é–‹é€£ç·šï¼š{addr}")
    #         self.clients.remove(conn)
    #         conn.close()
    #         print(f"ç›®å‰é€£ç·šæ•¸é‡ï¼š{self.get_client_count()}")

    def broadcast(self, message):

        chatmsg = ChatMsg(
            content=message,
            sender=self.name,
            type=MessageType.TEXT,
            timestamp=get_timestamp(),
        )

        msg = chat_msg_to_string(chatmsg)

        print(msg)
        for conn in self.clients:
            try:
                conn.sendall(msg.encode("utf-8"))
            except Exception as e:
                print(f"âš ï¸ å‚³é€éŒ¯èª¤ï¼š{e}")

    def close(self):
        if not self.is_running:
            print("âš ï¸ Server å°šæœªå•Ÿå‹•ã€‚")
            return
        print("ğŸ›‘ é—œé–‰ Server ä¸­...")
        self.is_running = False
        for conn in self.clients:
            try:
                conn.close()
            except:
                pass
        self.clients.clear()
        if self.server_socket:
            try:
                self.server_socket.close()
            except:
                pass
        print("âœ… Server å·²é—œé–‰")

    def get_client_count(self):
        return len(self.clients)

    def handle_client(self, conn, addr):
        client_key = str(addr)
        self.client_histories[client_key] = [
            {"role": "system", "content": SYSTEM_PROMPT}
        ]

        with conn:
            while self.is_running:
                try:
                    data = conn.recv(4096)
                    if not data:
                        print(f"âš ï¸ å®¢æˆ¶ç«¯æ–·é–‹é€£ç·šï¼š{addr}")
                        self.clients.remove(conn)
                        break

                    user_input = data.decode("utf-8")
                    print(f"User promptï¼š{user_input}")
                    json_obj = json.loads(user_input)

                    user_input = json_obj.get("content", "")

                    msg_type = MessageType(json_obj.get("type", "text"))

                    # ğŸ” åµæ¸¬æ˜¯å¦ç‚º base64 åœ–ç‰‡
                    if msg_type == MessageType.IMAGE:
                        print("ğŸ–¼ï¸ æ”¶åˆ°Image msgtype")
                        prompt = "è«‹æè¿°é€™å¼µåœ–ç‰‡çš„å…§å®¹ã€‚"

                        # å»ºç«‹ Vision æ¨¡å‹æ ¼å¼çš„ promptï¼Œä¾‹å¦‚ Ollama çš„æ ¼å¼
                        vision_payload = {
                            "model": "llava:latest",  # ç¢ºä¿ä½ æœ‰å®‰è£è©²æ¨¡å‹
                            "prompt": prompt,
                            "images": [user_input],
                            "stream": False,
                        }

                        response = requests.post(
                            "http://localhost:11434/api/generate", json=vision_payload
                        )
                        if response.status_code == 200:
                            ai_reply = response.json()["response"]
                            msg = ai_reply

                        else:
                            error_msg = f"[åœ–ç‰‡è™•ç†éŒ¯èª¤] {response.status_code}: {response.text}"
                            msg = error_msg

                        chatmsg = ChatMsg(
                            content=msg,
                            sender=self.name,
                            type=MessageType.TEXT,
                            timestamp=get_timestamp(),
                        )
                        conn.sendall(chatmsg.to_json().encode("utf-8"))

                    else:
                        # ğŸ“© ä¸€èˆ¬æ–‡å­—è™•ç†æµç¨‹
                        print(f"ğŸ“© æ”¶åˆ° promptï¼š{user_input}")

                        history = self.client_histories[client_key]
                        history.append({"role": "user", "content": user_input})

                        final_prompt = ""
                        for item in history:
                            role = item["role"].capitalize()
                            final_prompt += f"{role}: {item['content']}\n"

                        response = query_ollama(final_prompt)

                        chatmsg = ChatMsg(
                            content=response,
                            sender=self.name,
                            type=MessageType.TEXT,
                            timestamp=get_timestamp(),
                        )

                        chatmsg_str = chat_msg_to_string(chatmsg)
                        print(chatmsg_str)

                        print(f"ğŸ“¤ Ollama å›è¦†ï¼š{response}")
                        conn.sendall(chatmsg_str.encode("utf-8"))

                        history.append({"role": "assistant", "content": response})

                except Exception as e:
                    print(f"âš ï¸ å®¢æˆ¶ç«¯è™•ç†éŒ¯èª¤ï¼š{e}")
                    break


def list_ollama_models():
    url = "http://localhost:11434/api/tags"
    try:
        response = requests.get(url)
        if response.status_code == 200:
            models = response.json().get("models", [])
            if not models:
                print("âš ï¸ å°šæœªå®‰è£ä»»ä½•æ¨¡å‹ã€‚\n")
            else:
                print("âœ… æœ¬åœ°å¯ç”¨æ¨¡å‹ï¼š\n")
                for model in models:
                    print(f"ğŸ§  {model['name']}")
        else:
            print(f"âŒ æŸ¥è©¢å¤±æ•—ï¼š{response.status_code} - {response.text}")
    except requests.exceptions.RequestException as e:
        print("âŒ ç„¡æ³•é€£æ¥åˆ° Ollamaã€‚è«‹ç¢ºèªæ˜¯å¦å•Ÿå‹•ã€‚\n")
        print(str(e))


def is_base64_image(data_str):
    try:
        if data_str.startswith("data:image"):
            header, encoded = data_str.split(",", 1)
            base64.b64decode(encoded)
            return True
        return False
    except Exception:
        return False


if __name__ == "__main__":
    ip = input(f"Serverå•Ÿå‹• IP (é è¨­ {IP})ï¼š\n")
    port_input = input(f"Serverå•Ÿå‹•(é è¨­ {PORT}) portï¼š\n")

    if ip == "":
        ip = IP
    if port_input == "":
        port = PORT
    else:
        port = int(port_input)

    server = AIServer(ip, port)
    server.start()

    while True:
        cmd = input("è«‹è¼¸å…¥æŒ‡ä»¤ï¼š\n")

        if cmd == "/s":
            server.start()

        elif cmd == "/c":
            server.close()

        elif cmd == "/e":
            print("ğŸ‘‹ ç¨‹å¼çµæŸ")
            server.close()
            break
        elif cmd == "/count":
            print(f"ç›®å‰é€£ç·šæ•¸é‡ï¼š{server.get_client_count()}")

        else:
            server.broadcast(cmd)
